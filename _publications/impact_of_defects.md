---
title: "Impact of edge defects on the synaptic characteristic of a ferromagnetic domain-wall device and on on-chip learning"
collection: publications
permalink: /publications/impact_of_defects
excerpt: ' '
date: 2023-08-25
venue: 'Neuromorphic Computing and Engineering'
paperurl: 'https://iopscience.iop.org/article/10.1088/2634-4386/acf0e4'
citation: 'Ram Singh Yadav, Aniket Sadashiva, Amod Holla, Pranaba Kishor Muduli and Debanjan Bhowmik <br>
<i>Neuromorphic Computing and Engineering</i> <b>2023</b> <i>3</i> 034006 <br>
DOI: 10.1088/2634-4386/acf0e4'
---

**Abstract**: Topological-soliton-based devices, like the ferromagnetic domain-wall device, have been proposed as non-volatile memory (NVM) synapses in electronic crossbar arrays for fast and energy-efficient implementation of on-chip learning of neural networks (NN). High linearity and symmetry in the synaptic weight-update characteristic of the device (long-term potentiation (LTP) and long-term depression (LTD)) are important requirements to obtain high classification/regression accuracy in such an on-chip learning scheme. However, obtaining such linear and symmetric LTP and LTD characteristics in the ferromagnetic domain-wall device has remained a challenge. Here, we first carry out micromagnetic simulations of the device to show that the incorporation of defects at the edges of the device, with the defects having higher perpendicular magnetic anisotropy compared to the rest of the ferromagnetic layer, leads to massive improvement in the linearity and symmetry of the LTP and LTD characteristics of the device. This is because these defects act as pinning centres for the domain wall and prevent it from moving during the delay time between two consecutive programming current pulses, which is not the case when the device does not have defects. Next, we carry out system-level simulations of two crossbar arrays with synaptic characteristics of domain-wall synapse devices incorporated in them: one without such defects, and one with such defects. For on-chip learning of both long short-term memory networks (using a regression task) and fully connected NN (using a classification task), we show improved performance when the domain-wall synapse devices have defects at the edges. We also estimate the energy consumption in these synaptic devices and project their scaling, with respect to on-chip learning in corresponding crossbar arrays.